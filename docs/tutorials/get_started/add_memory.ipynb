{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11d0b567",
   "metadata": {},
   "source": [
    "# Agent memory\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/datascienceworld-kan/vinagent-docs/blob/main/docs/tutorials/get_started/add_memory.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b32896",
   "metadata": {},
   "source": [
    "`Vinagent` features a `Graphical Memory` system that transforms messages into a structured knowledge graph composed of nodes, relationships, and edges. This memory can be organized into short-term and long-term components, allowing the Agent to retain and recall learned information effectively.\n",
    "\n",
    "Compared to traditional `Conversational Memory, Graphical Memory` offers distinct advantages: it condenses essential information into a graph format, reducing hallucinations by filtering out redundant or irrelevant details. Additionally, because it operates with a shorter context length, it significantly lowers computational costs.\n",
    "\n",
    "This graph-based approach mirrors how humans conceptualize and retain knowledge, making it especially powerful for capturing the core meaning of complex conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bc5add",
   "metadata": {},
   "source": [
    "\n",
    "## Setup\n",
    "\n",
    "Install `vinagent` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ffd01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install vinagent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d347b2d",
   "metadata": {},
   "source": [
    "Write environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67932703",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile .env\n",
    "TOGETHER_API_KEY=\"Your together API key\"\n",
    "TAVILY_API_KEY=\"Your Tavily API key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bad119",
   "metadata": {},
   "source": [
    "## Initialize Agent\n",
    "\n",
    "Vinagent is outstanding with organizing Memory as a Knowledge Graph. We leverage AucoDB features to enhance graph's capabilities of agent. The graph-based features is supported as follows:\n",
    "\n",
    "- Graph Construction: Builds knowledge graphs from documents using LLMGraphTransformer class from AucoDB, extracting entities (nodes) and relationships with enriched properties such as categories, roles, or timestamps.\n",
    "\n",
    "- Property Enrichment: Enhances nodes and relationships with contextual attributes derived from the input text, improving graph expressiveness.\n",
    "\n",
    "- Graph Visualization: Visualizes the constructed graph and exports it as a html file for easy sharing and analysis.\n",
    "\n",
    "- Neo4j Integration: Stores and manages graphs in a Neo4j database with secure client initialization.\n",
    "\n",
    "- Flexible Input: Processes unstructured text to create structured graphs, suitable for applications like knowledge management, AI research, and data analysis.\n",
    "\n",
    "\n",
    "Prerequisites\n",
    "\n",
    "- Neo4j Database: A running Neo4j instance (local or remote).\n",
    "- Python Packages: Install required dependencies:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bce938",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-together neo4j python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b80cc60",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_together.chat_models import ChatTogether\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from vinagent.memory import Memory\n",
    "\n",
    "load_dotenv(find_dotenv('/Users/phamdinhkhanh/Documents/Courses/Manus/vinagent/.env'))\n",
    "\n",
    "llm = ChatTogether(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\"\n",
    ")\n",
    "\n",
    "memory = Memory(\n",
    "    memory_path=\"templates/memory.jsonl\",\n",
    "    is_reset_memory=True, # will reset the memory every time the agent is invoked\n",
    "    is_logging=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e77261f3",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 14:21:17,717 - INFO - HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-02 14:21:17,737 - INFO - Insert new line: {'head': 'Kan', 'head_type': 'Person', 'relation': 'BORN_IN', 'relation_properties': 'in 1993', 'tail': 'Thanh Hoa Province, Vietnam', 'tail_type': 'Location'}\n",
      "2025-07-02 14:21:17,738 - INFO - Insert new line: {'head': 'Kan', 'head_type': 'Person', 'relation': 'WORKS_FOR', 'relation_properties': 'since 2021', 'tail': 'FPT Software', 'tail_type': 'Company'}\n",
      "2025-07-02 14:21:17,738 - INFO - Insert new line: {'head': 'Kan', 'head_type': 'Person', 'relation': 'WORKS_FOR', 'relation_properties': 'since 2022', 'tail': 'NEU', 'tail_type': 'University'}\n",
      "2025-07-02 14:21:17,739 - INFO - Insert new line: {'head': 'Kan', 'head_type': 'Person', 'relation': 'STUDIED_AT', 'relation_properties': '', 'tail': 'High School for Gifted Students, VNU University', 'tail_type': 'School'}\n",
      "2025-07-02 14:21:17,739 - INFO - Insert new line: {'head': 'Kan', 'head_type': 'Person', 'relation': 'STUDIED_AT', 'relation_properties': 'graduated in 2015', 'tail': 'NEU University', 'tail_type': 'University'}\n",
      "2025-07-02 14:21:17,739 - INFO - Insert new line: {'head': 'Kan', 'head_type': 'Person', 'relation': 'RESEARCHED_AT', 'relation_properties': '', 'tail': 'FPT AIC', 'tail_type': 'Institution'}\n",
      "2025-07-02 14:21:17,740 - INFO - Insert new line: {'head': 'Kan', 'head_type': 'Person', 'relation': 'RECEIVED_AWARD', 'relation_properties': 'at Nvidia GTC Global Conference 2025', 'tail': 'paper award on Generative AI and LLMs', 'tail_type': 'Award'}\n",
      "2025-07-02 14:21:17,740 - INFO - Insert new line: {'head': 'Kan', 'head_type': 'Person', 'relation': 'FOUNDED', 'relation_properties': '', 'tail': 'DataScienceWorld.Kan', 'tail_type': 'Organization'}\n",
      "2025-07-02 14:21:17,741 - INFO - Insert new line: {'head': 'Kan', 'head_type': 'Person', 'relation': 'PARTICIPATED_IN', 'relation_properties': 'since 2024', 'tail': 'Google GDSC', 'tail_type': 'Event'}\n",
      "2025-07-02 14:21:17,741 - INFO - Insert new line: {'head': 'Kan', 'head_type': 'Person', 'relation': 'PARTICIPATED_IN', 'relation_properties': 'since 2024', 'tail': 'Google I/O', 'tail_type': 'Event'}\n",
      "2025-07-02 14:21:17,742 - INFO - Insert new line: {'head': 'DataScienceWorld.Kan', 'head_type': 'Organization', 'relation': 'OFFERS', 'relation_properties': '', 'tail': 'Build Generative AI Applications', 'tail_type': 'Course'}\n",
      "2025-07-02 14:21:17,742 - INFO - Insert new line: {'head': 'DataScienceWorld.Kan', 'head_type': 'Organization', 'relation': 'OFFERS', 'relation_properties': '', 'tail': 'MLOps – Machine Learning in Production', 'tail_type': 'Course'}\n",
      "2025-07-02 14:21:17,744 - INFO - Saved memory!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kan -> BORN_IN[in 1993] -> Thanh Hoa Province, Vietnam\n",
      "Kan -> WORKS_FOR[since 2021] -> FPT Software\n",
      "Kan -> WORKS_FOR[since 2022] -> NEU\n",
      "Kan -> STUDIED_AT -> High School for Gifted Students, VNU University\n",
      "Kan -> STUDIED_AT[graduated in 2015] -> NEU University\n",
      "Kan -> RESEARCHED_AT -> FPT AIC\n",
      "Kan -> RECEIVED_AWARD[at Nvidia GTC Global Conference 2025] -> paper award on Generative AI and LLMs\n",
      "Kan -> FOUNDED -> DataScienceWorld.Kan\n",
      "Kan -> PARTICIPATED_IN[since 2024] -> Google GDSC\n",
      "Kan -> PARTICIPATED_IN[since 2024] -> Google I/O\n",
      "DataScienceWorld.Kan -> OFFERS -> Build Generative AI Applications\n",
      "DataScienceWorld.Kan -> OFFERS -> MLOps – Machine Learning in Production\n"
     ]
    }
   ],
   "source": [
    "text_input = \"\"\"Hi, my name is Kan. I was born in Thanh Hoa Province, Vietnam, in 1993.\n",
    "My motto is: \"Make the world better with data and models\". That’s why I work as an AI Solution Architect at FPT Software and as an AI lecturer at NEU.\n",
    "I began my journey as a gifted student in Mathematics at the High School for Gifted Students, VNU University, where I developed a deep passion for Math and Science.\n",
    "Later, I earned an Excellent Bachelor's Degree in Applied Mathematical Economics from NEU University in 2015. During my time there, I became the first student from the Math Department to win a bronze medal at the National Math Olympiad.\n",
    "I have been working as an AI Solution Architect at FPT Software since 2021.\n",
    "I have been teaching AI and ML courses at NEU university since 2022.\n",
    "I have conducted extensive research on Reliable AI, Generative AI, and Knowledge Graphs at FPT AIC.\n",
    "I was one of the first individuals in Vietnam to win a paper award on the topic of Generative AI and LLMs at the Nvidia GTC Global Conference 2025 in San Jose, USA.\n",
    "I am the founder of DataScienceWorld.Kan, an AI learning hub offering high-standard AI/ML courses such as Build Generative AI Applications and MLOps – Machine Learning in Production, designed for anyone pursuing a career as an AI/ML engineer.\n",
    "Since 2024, I have participated in Google GDSC and Google I/O as a guest speaker and AI/ML coach for dedicated AI startups.\n",
    "\"\"\"\n",
    "\n",
    "memory.save_short_term_memory(llm, text_input, user_id=\"Kan\")\n",
    "memory_message = memory.load_memory_by_user(load_type='string', user_id=\"Kan\")\n",
    "print(memory_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d4af1f",
   "metadata": {},
   "source": [
    "## Load memory by user_id\n",
    "\n",
    "Memory is organized by `user_id` to segment each user’s data within the long-term memory. Before starting a conversation, the agent can access the memory associated with the given `user_id`, which helps prevent confusion between users the agent has previously interacted with and toward on a more personalized experience. For instance, if the agent has a conversation with Mr. Kan, it can recall all that information in future sessions by referencing `user_id='Kan'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d21ede28",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "message_user = memory.load_memory_by_user(load_type='list', user_id=\"Kan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3027d07a",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'head': 'Kan',\n",
       "  'head_type': 'Person',\n",
       "  'relation': 'BORN_IN',\n",
       "  'relation_properties': 'in 1993',\n",
       "  'tail': 'Thanh Hoa Province, Vietnam',\n",
       "  'tail_type': 'Location'},\n",
       " {'head': 'Kan',\n",
       "  'head_type': 'Person',\n",
       "  'relation': 'WORKS_FOR',\n",
       "  'relation_properties': 'since 2021',\n",
       "  'tail': 'FPT Software',\n",
       "  'tail_type': 'Company'},\n",
       " {'head': 'Kan',\n",
       "  'head_type': 'Person',\n",
       "  'relation': 'WORKS_FOR',\n",
       "  'relation_properties': 'since 2022',\n",
       "  'tail': 'NEU',\n",
       "  'tail_type': 'University'},\n",
       " {'head': 'Kan',\n",
       "  'head_type': 'Person',\n",
       "  'relation': 'STUDIED_AT',\n",
       "  'relation_properties': '',\n",
       "  'tail': 'High School for Gifted Students, VNU University',\n",
       "  'tail_type': 'School'},\n",
       " {'head': 'Kan',\n",
       "  'head_type': 'Person',\n",
       "  'relation': 'STUDIED_AT',\n",
       "  'relation_properties': 'graduated in 2015',\n",
       "  'tail': 'NEU University',\n",
       "  'tail_type': 'University'},\n",
       " {'head': 'Kan',\n",
       "  'head_type': 'Person',\n",
       "  'relation': 'RESEARCHED_AT',\n",
       "  'relation_properties': '',\n",
       "  'tail': 'FPT AIC',\n",
       "  'tail_type': 'Institution'},\n",
       " {'head': 'Kan',\n",
       "  'head_type': 'Person',\n",
       "  'relation': 'RECEIVED_AWARD',\n",
       "  'relation_properties': 'at Nvidia GTC Global Conference 2025',\n",
       "  'tail': 'paper award on Generative AI and LLMs',\n",
       "  'tail_type': 'Award'},\n",
       " {'head': 'Kan',\n",
       "  'head_type': 'Person',\n",
       "  'relation': 'FOUNDED',\n",
       "  'relation_properties': '',\n",
       "  'tail': 'DataScienceWorld.Kan',\n",
       "  'tail_type': 'Organization'},\n",
       " {'head': 'Kan',\n",
       "  'head_type': 'Person',\n",
       "  'relation': 'PARTICIPATED_IN',\n",
       "  'relation_properties': 'since 2024',\n",
       "  'tail': 'Google GDSC',\n",
       "  'tail_type': 'Event'},\n",
       " {'head': 'Kan',\n",
       "  'head_type': 'Person',\n",
       "  'relation': 'PARTICIPATED_IN',\n",
       "  'relation_properties': 'since 2024',\n",
       "  'tail': 'Google I/O',\n",
       "  'tail_type': 'Event'},\n",
       " {'head': 'DataScienceWorld.Kan',\n",
       "  'head_type': 'Organization',\n",
       "  'relation': 'OFFERS',\n",
       "  'relation_properties': '',\n",
       "  'tail': 'Build Generative AI Applications',\n",
       "  'tail_type': 'Course'},\n",
       " {'head': 'DataScienceWorld.Kan',\n",
       "  'head_type': 'Organization',\n",
       "  'relation': 'OFFERS',\n",
       "  'relation_properties': '',\n",
       "  'tail': 'MLOps – Machine Learning in Production',\n",
       "  'tail_type': 'Course'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2bc16",
   "metadata": {},
   "source": [
    "## Visualize on Neo4j\n",
    "\n",
    "You can explore the knowledge graph on-premise using the Neo4j dashboard at `http://localhost:7474/browser/`. This allows you to intuitively understand the nodes and relationships within your data.\n",
    "\n",
    "To enable this visualization, the `AucoDBNeo4jClient`, a client instance from the `AucoDB` library, supports ingesting graph memory directly into a `Neo4j` database. Once the data is ingested, you can use `Cypher` queries to retrieve nodes and edges for inspection or further analysis.\n",
    "\n",
    "**Note:**\n",
    "Authentication: Access to the Neo4j dashboard requires login using the same `username/password` credentials configured in your Docker environment (e.g., via the NEO4J_AUTH variable).\n",
    "\n",
    "If you prefer not to use the `Neo4j` web interface, the `AucoDBNeo4jClient` also provides a convenient method to export the entire graph to an HTML file, which is `client.visualize_graph(output_path=\"my_graph.html\")`.\n",
    "\n",
    "This method generates a standalone HTML file containing an interactive graph visualization, ideal for embedding in reports or sharing with others without requiring Neo4j access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca97adf",
   "metadata": {},
   "source": [
    "### Start Neo4j service\n",
    "\n",
    "Neo4j database can be install as a docker service. We need to create a `docker-compose.yml` file on local and start `Neo4j` database as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9439751a",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile docker-compose.yml\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  neo4j:\n",
    "    image: neo4j:latest\n",
    "    container_name: neo4j\n",
    "    ports:\n",
    "      - \"7474:7474\"\n",
    "      - \"7687:7687\"\n",
    "    environment:\n",
    "      - NEO4J_AUTH=neo4j/abc@12345"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456009bd",
   "metadata": {},
   "source": [
    "Start `neo4j` service by command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea8f182",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "docker-compose up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcb9c0e",
   "metadata": {},
   "source": [
    "### Export Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b273723e",
   "metadata": {},
   "source": [
    "Install dependency `AucoDB` library to ingest knowledge graph to `Neo4j` database and and export graph to html file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b145ddd3",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "%pip install aucodb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eea161",
   "metadata": {},
   "source": [
    "Initialze client instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d6b8c",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_together.chat_models import ChatTogether\n",
    "from aucodb.graph.neo4j_client import AucoDBNeo4jClient\n",
    "from aucodb.graph import LLMGraphTransformer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Step 1: Initialize AucoDBNeo4jClient\n",
    "# Method 1: dirrectly passing arguments, but not ensure security\n",
    "NEO4J_URI = \"bolt://localhost:7687\"  # Update with your Neo4j URI\n",
    "NEO4J_USER = \"neo4j\"  # Update with your Neo4j username\n",
    "NEO4J_PASSWORD = \"abc@12345\"  # Update with your Neo4j password\n",
    "\n",
    "client = AucoDBNeo4jClient(uri = NEO4J_URI, user = NEO4J_USER, password = NEO4J_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a04d36",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Save user memory into jsonline\n",
    "import json\n",
    "\n",
    "with open(\"user_memory.jsonl\", \"w\") as f:\n",
    "    for item in message_user:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4129d30",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Load user_memory.jsonl into Neo4j.\n",
    "client.load_json_to_neo4j(\n",
    "    json_file='user_memory.jsonl',\n",
    "    is_reset_db=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef2b5d1",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Export graph into my_graph.html file.\n",
    "client.visualize_graph(output_file=\"my_graph.html\", show_in_browser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff15b4ce",
   "metadata": {},
   "source": [
    "![](docs/site/assets/images/my_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c137db6a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
